<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="tensorflow,机器学习,神经网络,卷积神经网络,CNN,翻译," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="内容翻译自Deep MNIST for Experts
本文可能插入TensorFlow官网上的图片或者链接，需翻墙可以加载或访问。
TenforFlow是一个强大的大规模数字计算的软件包。它擅长的功能之一是实现并且训练深度神经网络。在这个教程中，我们将会学习构建一个基本的深度卷积MNIST分类模型，
关于这个教程这个教程的第一部分解释在mnist_softmax.py代码中实现了什么，这是Ten">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow——MNIST手写字符识别">
<meta property="og:url" content="http://yoursite.com/2017/04/08/TensorFlow——MNIST手写字符识别/index.html">
<meta property="og:site_name" content="jlearning.cn">
<meta property="og:description" content="内容翻译自Deep MNIST for Experts
本文可能插入TensorFlow官网上的图片或者链接，需翻墙可以加载或访问。
TenforFlow是一个强大的大规模数字计算的软件包。它擅长的功能之一是实现并且训练深度神经网络。在这个教程中，我们将会学习构建一个基本的深度卷积MNIST分类模型，
关于这个教程这个教程的第一部分解释在mnist_softmax.py代码中实现了什么，这是Ten">
<meta property="og:updated_time" content="2017-04-08T14:03:34.493Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TensorFlow——MNIST手写字符识别">
<meta name="twitter:description" content="内容翻译自Deep MNIST for Experts
本文可能插入TensorFlow官网上的图片或者链接，需翻墙可以加载或访问。
TenforFlow是一个强大的大规模数字计算的软件包。它擅长的功能之一是实现并且训练深度神经网络。在这个教程中，我们将会学习构建一个基本的深度卷积MNIST分类模型，
关于这个教程这个教程的第一部分解释在mnist_softmax.py代码中实现了什么，这是Ten">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/04/08/TensorFlow——MNIST手写字符识别/"/>





  <title> TensorFlow——MNIST手写字符识别 | jlearning.cn </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">jlearning.cn</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/08/TensorFlow——MNIST手写字符识别/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Zhuo Jimmy">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="jlearning.cn">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="jlearning.cn" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                TensorFlow——MNIST手写字符识别
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-08T22:01:55+08:00">
                2017-04-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>内容翻译自<a href="https://www.tensorflow.org/get_started/mnist/pros" target="_blank" rel="external">Deep MNIST for Experts</a></p>
<p>本文可能插入TensorFlow官网上的图片或者链接，需翻墙可以加载或访问。</p>
<p>TenforFlow是一个强大的大规模数字计算的软件包。它擅长的功能之一是实现并且训练深度神经网络。在这个教程中，我们将会学习构建一个基本的深度卷积MNIST分类模型，</p>
<h2 id="关于这个教程"><a href="#关于这个教程" class="headerlink" title="关于这个教程"></a>关于这个教程</h2><p>这个教程的第一部分解释在<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/mnist/mnist_softmax.py" target="_blank" rel="external">mnist_softmax.py</a>代码中实现了什么，这是TensorFlow模型实现的基础。第二部分展示一些提高精确度的方法。</p>
<p>在这个教程中我们将会完成以下几点：</p>
<ul>
<li>建立一个softmax回归函数作为识别MNIST数字的模型，基于观察图片中的每一个像素。</li>
<li>使用TensorFlow训练这个模型去识别图片，通过观察成千的样本。</li>
<li>使用测试数据验证模型的精确度。</li>
<li>建立、训练、测试一个多层卷积神经网络，来提升结果。</li>
</ul>
<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>开始之前，要先加载MNIST数据集，然后开始一个TensorFlow session</p>
<h3 id="加载MNIST数据"><a href="#加载MNIST数据" class="headerlink" title="加载MNIST数据"></a>加载MNIST数据</h3><p>复制粘贴下面的代码，程序会自动下载读取数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</div><div class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST_data'</span>, one_hot=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<p>这里<code>mnist</code>是一个轻量的类储存训练、验证、测试数据，以NumPy数组的方式。其也提供了一个迭代小批的函数，我们下面会用到。</p>
<h3 id="开始TensorFlow-InterativeSession"><a href="#开始TensorFlow-InterativeSession" class="headerlink" title="开始TensorFlow InterativeSession"></a>开始TensorFlow InterativeSession</h3><p>TensorFlow在后端依靠高效的C++来执行计算。与后端的连接叫做<code>sessioin</code>。TensorFlow程序常见的用法是创建一个<code>graph</code>，然后再一个<code>session</code>中启动它。</p>
<p>这里我们选择使用方便的<code>InteractiveSession</code>类，它会让TensorFlow中你组织你的代码更灵活。它循序你交替运行建立一个计算图和运行这个图的操作。（ It allows you tointerleave operations which build a <a href="https://www.tensorflow.org/get_started/get_started#the_computational_graph" target="_blank" rel="external">computation graph</a> with ones that run the graph. ）这在例如IPython的交互式的环境中特别方便。如果你不使用<code>InteractiveSesion</code>，你应该建立一个完整的图在你启动session和运行这个图之前。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line">sess = tf.InteractiveSession()</div></pre></td></tr></table></figure>
<h3 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h3><p>为了在Python中高效的进行数值计算，我们使用像NumPy的包来在Python以外进行重量级运算，例如矩阵乘法。不幸的是，每个操作仍然有很多切换回Python的开销。如果你想运行这些计算在GPU上或者以分布式的形式这些在转换数据时有大量消耗的方式，这些开销变的相当昂贵。</p>
<p>TensorFlow也是把这些重量操作放在Python外面，但是它做了一些设定去避免这些开销。TensorFlow允许我们描述一个图在Python外面运行的交互操作，而不是使用Python运行一个单独的重量操作。这个方法和在Theano和Torch中的方法很像。</p>
<p>Python代码的作用是建立一个外部计算图，然后命令运算图的哪一部分应该被执行。查看<a href="https://www.tensorflow.org/get_started/get_started#the_computational_graph" target="_blank" rel="external">Computation Graph</a>和<a href="https://www.tensorflow.org/get_started/get_started" target="_blank" rel="external">Getting Started With TensorFlow</a>获得更多细节。</p>
<h2 id="建立一个Softmax回归模型"><a href="#建立一个Softmax回归模型" class="headerlink" title="建立一个Softmax回归模型"></a>建立一个Softmax回归模型</h2><p>在这一部分，我们建立一个单层softmax回归模型，下一节我们将模型扩展为多层卷积网络。</p>
<h3 id="占位符"><a href="#占位符" class="headerlink" title="占位符"></a>占位符</h3><p>我们通过创建输入图像的节点和输出类别的节点来建立计算图：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">x = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">784</span>])</div><div class="line">y_ = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">10</span>])</div></pre></td></tr></table></figure>
<p>输入的图像x由二维浮点数<code>tensor</code>组成。我们分配一个<code>[None,784]</code> 的<code>shape</code>。784是28*28图像，None代表第一位由每一批的数量决定。目标输出类别<code>y_</code>由二维<code>tensor</code>组成，每行是一个十维的矢量表示类别（0或者1）。</p>
<p><code>placeholder</code> 的<code>shape</code>参数是可选择的，但是它允许TensorFlow在<code>shape</code>不一致的时候自动的捕获bug。</p>
<h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><p>我们定义权重<code>W</code>和偏置量<code>b</code>，我们可以设想通过额外的输入训练这些量。但是TensorFlow有一种更好的方式管理他们：<code>variable</code>。一个<code>varable</code>是TensorFlow的计算图中的一个值。他可以根据计算修改。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>,<span class="number">10</span>]))</div><div class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</div></pre></td></tr></table></figure>
<p>我们在调用<code>tf.Variable</code>的时候传入一个初始值。在这个例子中，我们将w和b都初始为0.</p>
<p>在<code>Varialbe</code>在session中调用之前，他们必须使用这个session初始化。这一步让已经指定的初始值赋值给每个变量。可以为所有变量一次性全部初始化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sess.run(tf.global_variables_initializer())</div></pre></td></tr></table></figure>
<h3 id="预测类别以及损失函数"><a href="#预测类别以及损失函数" class="headerlink" title="预测类别以及损失函数"></a>预测类别以及损失函数</h3><p>我们现在可以实现我们的回归模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">y = tf.matmul(x,W) + b</div></pre></td></tr></table></figure>
<p>我们可以和这一样简单的指定损失函数。这里，我们的损失函数是目标和这个预测模型softmax激活函数的交叉熵。作为初级教程，我们使用这个保险的形式:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cross_entropy = tf.reduce_mean(</div><div class="line">    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))</div></pre></td></tr></table></figure>
<p>注意这里<code>tf.nn.softmax_corss_entropy_with_logits</code>internally(内部地) applies the softmax on the model’s unnormalized model prediction and sums across all classes。<code>tf.reduce_mean</code>求这些和的平均数。</p>
<h2 id="训练这个模型"><a href="#训练这个模型" class="headerlink" title="训练这个模型"></a>训练这个模型</h2><p>现在我们已经定义了我们的模型和损失函数，这让使用TensorFlow训练很简单。因为TensorFlow知道了所有的计算图，他可以使用自动的计算损失函数对于每一个变量的导数。TensorFlow有很多不同的<a href="https://www.tensorflow.org/api_guides/python/train#optimizers" target="_blank" rel="external">自带最优化算法</a>。例如我们使用梯度下降法，步长0.5去减少交叉熵：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>).minimize(cross_entropy)</div></pre></td></tr></table></figure>
<p>这里在计算图上增加了一个新的操作，这个操作包含计算梯度、计算参数更新量、然后更新参数。</p>
<p>运行时被返回的操作<code>train_step</code>会应用到梯度下降中更新参数。因此，训练这个模型可以不停的运行<code>train_step</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1000</span>):</div><div class="line">  batch = mnist.train.next_batch(<span class="number">100</span>)</div><div class="line">  train_step.run(feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>]&#125;)</div></pre></td></tr></table></figure>
<p>我们在每次训练迭代的时候加载100条训练样本。当我们运行<code>train_step</code>操作，使用<code>feed_dict</code>去取代<code>placeholder</code>tensors<code>x</code>和<code>y_</code>。注意，你可以使用<code>feed_dict</code>替代任何tensor在你的计算图中，不仅仅是<code>placeholder</code>.</p>
<h3 id="评价这个模型"><a href="#评价这个模型" class="headerlink" title="评价这个模型"></a>评价这个模型</h3><p>首先我们计算出我们预测正确标签的位置。<code>tf.argmax</code>是一个特别有用的函数，可以给你tensor中最高标量的索引。例如<code>tf.argmax(y,1)</code>是我们模型认为最有可能的结果，当<code>tf.argmax(y_,1)</code>是一个正确的标签。我们使用<code>tf.equal</code>去检查我们的预测是否正确：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))</div></pre></td></tr></table></figure>
<p>返回我们一个布尔值。为了确定正确率，我们转换为浮点数，然后计算他们的平均数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</div></pre></td></tr></table></figure>
<p>最终我们评价在测试数据上的精确度：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">print(accuracy.eval(feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;))</div></pre></td></tr></table></figure>
<h2 id="构建一个多层卷积网络"><a href="#构建一个多层卷积网络" class="headerlink" title="构建一个多层卷积网络"></a>构建一个多层卷积网络</h2><h3 id="权重初始化"><a href="#权重初始化" class="headerlink" title="权重初始化"></a>权重初始化</h3><p>为了建立这个模型，我们将需要很多权重和偏置量。应该用一个很小的量初始化这些权重来打破对称，和预防0梯度。所以，我们使用<a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks" target="_blank" rel="external">ReLU</a>)神经细胞。用一些小的正值初始化偏置量可以避免”死神经细胞“。为了防止在建立模型时重复这一过程，我们建立两个方便的函数去做这些事情：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></div><div class="line">  initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</div><div class="line">  <span class="keyword">return</span> tf.Variable(initial)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></div><div class="line">  initial = tf.constant(<span class="number">0.1</span>, shape=shape)</div><div class="line">  <span class="keyword">return</span> tf.Variable(initial)</div></pre></td></tr></table></figure>
<h3 id="卷积和池化"><a href="#卷积和池化" class="headerlink" title="卷积和池化"></a>卷积和池化</h3><p>TensorFlow也给予我们在在卷积和池化中很多灵活性。我们要怎样处理边界？步长多少？在这个例子中，我们将选择vanilla版本。我们的卷积使用步长1，pad 0.所以，输出和输入的规格是一样的。我们2*2格子中选择最大池化。为了保持代码整洁，仍然建立两个函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W)</span>:</span></div><div class="line">  <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x)</span>:</span></div><div class="line">  <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</div><div class="line">                        strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</div></pre></td></tr></table></figure>
<p><strong>padding</strong> :步长不能整除图片大小时边距的处理方法，“SAME”表示超过边界用0填充，使得输出保持和输入相同的大小，“VALID”表示不超过边界，通常会丢失一些信息。</p>
<h3 id="第一个卷积层"><a href="#第一个卷积层" class="headerlink" title="第一个卷积层"></a>第一个卷积层</h3><p>我们可以实现我们的第一层。卷积将会计算5*5patch的32个特征。权重tensor的shape是[5,5,1,32]。前两个维度是patch大小。下一个数字是输入频道数，最后一个是输出频道数。而且我们将为每个输出加上一个偏置量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">W_conv1 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>])</div><div class="line">b_conv1 = bias_variable([<span class="number">32</span>])</div></pre></td></tr></table></figure>
<p>我们先将<code>x</code>改造成4维的tensor。第二第三维对应图像的宽和长，最后一维对应彩色通道（channel）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x_image = tf.reshape(x, [<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>])</div></pre></td></tr></table></figure>
<p>使用权重卷积，加上偏置量，应用ReLU函数，最后最大池化。池化将会把图片大小改变为14*14.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</div><div class="line">h_pool1 = max_pool_2x2(h_conv1)</div></pre></td></tr></table></figure>
<h3 id="第二个卷积层"><a href="#第二个卷积层" class="headerlink" title="第二个卷积层"></a>第二个卷积层</h3><p>第二层有对于每个5*5的patch，有64个特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">W_conv2 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>])</div><div class="line">b_conv2 = bias_variable([<span class="number">64</span>])</div><div class="line"></div><div class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</div><div class="line">h_pool2 = max_pool_2x2(h_conv2)</div></pre></td></tr></table></figure>
<h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">W_fc1 = weight_variable([<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>])</div><div class="line">b_fc1 = bias_variable([<span class="number">1024</span>])</div><div class="line"></div><div class="line">h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</div><div class="line">h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</div></pre></td></tr></table></figure>
<h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><p>为了减少过拟合，我们在输出之前应用<a href="https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf" target="_blank" rel="external">dropout</a>。我们创建一个神经元输出概率的<code>placeholder</code>。在训练的时候弃用，在测试的时候关闭。TensorFlow的<code>tf.nn.dropout</code>自动的控制神经输出时mask他们。所以dropout不需要额外的值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">keep_prob = tf.placeholder(tf.float32)</div><div class="line">h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</div></pre></td></tr></table></figure>
<h3 id="输出层"><a href="#输出层" class="headerlink" title="输出层"></a>输出层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">W_fc2 = weight_variable([<span class="number">1024</span>, <span class="number">10</span>])</div><div class="line">b_fc2 = bias_variable([<span class="number">10</span>])</div><div class="line"></div><div class="line">y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2</div></pre></td></tr></table></figure>
<h3 id="训练并且评价这个模型"><a href="#训练并且评价这个模型" class="headerlink" title="训练并且评价这个模型"></a>训练并且评价这个模型</h3><p>和softmax神经网络的区别：</p>
<ul>
<li>使用复杂的ADAM optimizer取代梯度下降法。</li>
<li>在<code>feed_dict</code> 中使用<code>keep_prob</code>控制dropout率。</li>
<li>训练过程中x每100次迭代输出一次日志。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">cross_entropy = tf.reduce_mean(</div><div class="line">    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))</div><div class="line">train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy)</div><div class="line">correct_prediction = tf.equal(tf.argmax(y_conv,<span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</div><div class="line">sess.run(tf.global_variables_initializer())</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20000</span>):</div><div class="line">  batch = mnist.train.next_batch(<span class="number">50</span>)</div><div class="line">  <span class="keyword">if</span> i%<span class="number">100</span> == <span class="number">0</span>:</div><div class="line">    train_accuracy = accuracy.eval(feed_dict=&#123;</div><div class="line">        x:batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">1.0</span>&#125;)</div><div class="line">    print(<span class="string">"step %d, training accuracy %g"</span>%(i, train_accuracy))</div><div class="line">  train_step.run(feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">0.5</span>&#125;)</div><div class="line"></div><div class="line">print(<span class="string">"test accuracy %g"</span>%accuracy.eval(feed_dict=&#123;</div><div class="line">    x: mnist.test.images, y_: mnist.test.labels, keep_prob: <span class="number">1.0</span>&#125;))</div></pre></td></tr></table></figure>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/tensorflow/" rel="tag"># tensorflow</a>
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/神经网络/" rel="tag"># 神经网络</a>
          
            <a href="/tags/卷积神经网络/" rel="tag"># 卷积神经网络</a>
          
            <a href="/tags/CNN/" rel="tag"># CNN</a>
          
            <a href="/tags/翻译/" rel="tag"># 翻译</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/04/07/TensorFlow入门——线性回归的例子/" rel="next" title="TensorFlow入门——线性回归的例子">
                <i class="fa fa-chevron-left"></i> TensorFlow入门——线性回归的例子
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/04/09/《深入理解java虚拟机》读书笔记（二）——Java内存/" rel="prev" title="《深入理解java虚拟机》读书笔记（二）——Java内存">
                《深入理解java虚拟机》读书笔记（二）——Java内存 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="lv-container" data-id="city" data-uid="MTAyMC8yNzkwNS80NDgy"></div>
    
  </div>

    
        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="Zhuo Jimmy" />
          <p class="site-author-name" itemprop="name">Zhuo Jimmy</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">17</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">31</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/u/2116491901" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="mailto:zhuo_jimmy@yeah.net" target="_blank" title="email">
                  
                    <i class="fa fa-fw fa-envelope"></i>
                  
                  email
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#关于这个教程"><span class="nav-number">1.</span> <span class="nav-text">关于这个教程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#准备"><span class="nav-number">2.</span> <span class="nav-text">准备</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#加载MNIST数据"><span class="nav-number">2.1.</span> <span class="nav-text">加载MNIST数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#开始TensorFlow-InterativeSession"><span class="nav-number">2.2.</span> <span class="nav-text">开始TensorFlow InterativeSession</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#计算图"><span class="nav-number">2.3.</span> <span class="nav-text">计算图</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#建立一个Softmax回归模型"><span class="nav-number">3.</span> <span class="nav-text">建立一个Softmax回归模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#占位符"><span class="nav-number">3.1.</span> <span class="nav-text">占位符</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#变量"><span class="nav-number">3.2.</span> <span class="nav-text">变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#预测类别以及损失函数"><span class="nav-number">3.3.</span> <span class="nav-text">预测类别以及损失函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#训练这个模型"><span class="nav-number">4.</span> <span class="nav-text">训练这个模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#评价这个模型"><span class="nav-number">4.1.</span> <span class="nav-text">评价这个模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#构建一个多层卷积网络"><span class="nav-number">5.</span> <span class="nav-text">构建一个多层卷积网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#权重初始化"><span class="nav-number">5.1.</span> <span class="nav-text">权重初始化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积和池化"><span class="nav-number">5.2.</span> <span class="nav-text">卷积和池化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#第一个卷积层"><span class="nav-number">5.3.</span> <span class="nav-text">第一个卷积层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#第二个卷积层"><span class="nav-number">5.4.</span> <span class="nav-text">第二个卷积层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#全连接层"><span class="nav-number">5.5.</span> <span class="nav-text">全连接层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dropout"><span class="nav-number">5.6.</span> <span class="nav-text">Dropout</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#输出层"><span class="nav-number">5.7.</span> <span class="nav-text">输出层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练并且评价这个模型"><span class="nav-number">5.8.</span> <span class="nav-text">训练并且评价这个模型</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhuo Jimmy</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	




  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  



  
  

  
  


  

  

  


</body>
</html>
